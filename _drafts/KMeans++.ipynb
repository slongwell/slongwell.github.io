{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# KMeans++ Initialization\n",
    "[Arthur and Vassilvitskii, 2006](http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf)  \n",
    "KMeans is a clustering algorithm.  \n",
    "\"K\" refers to the number of cluster centers.  \n",
    "\"Means\" refers to the means (centroids) of data in a cluster.  \n",
    "\n",
    "In KMeans, there are many ways to choose initial cluster centers.  \n",
    "The \"++\" of KMeans++ refers to an initialization procedure that distributes initial cluster centers across the data. It takes longer than many initialization procedures, but it greatly reduces the number of KMeans iterations needed to converge and tends to give better clusterings.\n",
    "\n",
    "###Algorithm: \n",
    "\n",
    "$\n",
    "\\begin{array} {lll}\n",
    "\\hline\n",
    "In & k & \\text{number of cluster centers} \\\\\n",
    "   & data & \\text{rows of data points to be clustered} \\\\\n",
    "\\hline\n",
    "Out & centroids & \\text{locations of initial cluster centers} \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "\n",
    "1. Pick a random **data point** (row vector) as the first **cluster center**. Store this row vector in a vector of length **k**.\n",
    "2. Until **k cluster centers** have been chosen:\n",
    "    1. For *every* **data point**: calculate the minimum SSD to *any* of the stored **cluster centers**. Store these minimum distances, one per **data point**, in a vector. (SSD is the sum of differences squared == Euclidean distance squared.)\n",
    "    2. Convert the vector of SSD values to a discrete probability distribution (divide by the sum of the vector). Use this probability distribution to weight the selection of another **data point** as the next **cluster center**.* \n",
    "\n",
    "*Note: a data point that has already been selected has 0 probability of being selected again: its SSD to the nearest center is 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Implements kmeans++ initialization in Python\n",
    "# Assumes row vectors are data points that will be clustered\n",
    "\n",
    "# In: k (int; number of centroids), data (array; data to be clustered)\n",
    "# Out: centroids (matrix; initial centroid locations)\n",
    "def centroidInit(k, data):\n",
    "\tnRows = data.shape[0]\n",
    "\tif k > nRows:\n",
    "\t\t# print \"Warning: k exceeds number of data points\"\n",
    "\t\t# print \"Setting k to number of data points: \" + str(nRows)\n",
    "\t\tk = nRows\n",
    "\tcentroids = np.empty((k, data.shape[1])) # matrix (row = a centroid)\n",
    "\t\n",
    "\t# for each data row, will hold *minimum* sum of difference squared (Euclidean squared)\n",
    "\t# to any already chosen centroid\n",
    "\tD2 = np.full(nRows, float(\"inf\"))\n",
    "\n",
    "\t# pick random data row to be first centroid\n",
    "\tiRow = np.random.randint(nRows)\n",
    "\tcentroids[0] = data[iRow]\n",
    "\n",
    "\t# select additional data rows\n",
    "\tfor i_k in xrange(0,k-1):\n",
    "\t\tD2 = np.minimum(((data-centroids[i_k])**2).sum(axis=1), D2)  # update D2 with min distances\n",
    "\t\tiRow = np.random.choice(nRows, p=D2/D2.sum()) # convert D2 to discrete probability distribution\n",
    "\t\tcentroids[i_k+1] = data[iRow]\n",
    "\treturn centroids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
